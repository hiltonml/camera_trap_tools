{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Generic_Animal_Detector.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyM4QB8fvY8zSLlW9Ymoo+yA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"EllWA93FSli0"},"source":["# Training a Single Species Animal Detector with Transfer Learning\n","### Mike Hilton, Eckerd College, 31 August 2021\n","\n","This Colab presents the use of transfer learning to create an image classifier that detects if a focal species is present in an image or not.  The detector produced by this colab is suitable for use with the autocopy.py program in the Eckerd Camera Trap Tools suite.\n","\n","The EfficientNetB0 model is used as the starting point.  This model expects a 224 x 224-pixel 24-bit color image as input.\n","\n","The training data should be provided in two folders: a folder named \"background\" containing images that do not include the focal species, and a folder named \"present\" containing images that do include the focal species.  At least 150 images of each class should be provided and the number of images in each folder should be roughly the same.  \n","\n"]},{"cell_type":"markdown","metadata":{"id":"TNPFvhpccyBT"},"source":["The image folders can exist on your Google Drive, or be uploaded to the runtime Colab instance using the folder icon in the leftmost Colab pane. This notebook demonstrates the Google Drive approach.\n","\n","Mount Google Drive to get access to the training dataset.  Follow the instructions printed on the screen when you run the code section below."]},{"cell_type":"code","metadata":{"id":"IkpHaHENvggu"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0f-MbyAUt1Lg"},"source":["Load the Python modules needed"]},{"cell_type":"code","metadata":{"id":"Uyrv2dwPrJXS"},"source":["\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import pandas\n","import pickle\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","from sklearn.preprocessing import LabelBinarizer\n","import tensorflow as tf\n","import tensorflow.keras as keras"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-WbQA-NDt4fN"},"source":["Initialize global variables controlling the training process.  You should modify the values as needed."]},{"cell_type":"code","metadata":{"id":"CLquOOlisO0N"},"source":["# Location of training data folder\n","DATASET_PATH = \"/content/gdrive/MyDrive/Colab Notebooks/training_images\"  \n","\n","# Path to saved model\n","SAVED_MODEL_PATH = \"/content/gdrive/MyDrive/Colab Notebooks/saved_models/generic_detector.h5\"  \n","\n","# Path to the saved category label binarizer\n","LABEL_ENCODER_PATH = \"/content/gdrive/MyDrive/Colab Notebooks/saved_models/generic_detector_label_encoder.pickle\"\n","\n","# Number of training images in each class to use; -1 means use all images in dataset.\n","# If you have a lot of images, you might consider first testing this notebook on a\n","# small subset of the images to make sure everything works to your satisfaction.  Then\n","# you can change IMAGE_COUNT to -1 to train with all images.\n","IMAGE_COUNT = 20                       \n","\n","# Size of images handled by EfficientNetB0.  You should not change this value unless\n","# you switch to using a different CNN architecture.\n","INPUT_DIMS = (224, 224)                 \n","\n","# Training batch size.  If you are not familiar with how CNN's are trainined, I \n","# recommend not changing this value.\n","BS = 32 \n","\n","## PHASE ONE of transfer learning is when the classification head of the CNN is\n","## trained.  The feature extraction network is frozen and does not change during \n","## phase one.\n","# Number of training epochs during phase 1 of training.  An epoch is one complete \n","# pass over the training dataset.\n","PHASE1_EPOCHS = 40 \n","# learning rate during phase 1 of training\n","PHASE1_LR = 1e-3   \n","\n","## PHASE TWO of transfer learning is when the last layers of the feature extraction\n","## network are unfrozen and fine-tuned to learn about you dataset.\n","PHASE2_EPOCHS = 10                       \n","PHASE2_LR = 1e-4                       "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J2dffl9HtSCB"},"source":["Define functions to load an image dataset from disk and prepare it for use with EfficientNet."]},{"cell_type":"code","metadata":{"id":"pyhwDL19sT_I"},"source":["def load_image(image_path):\n","  \"\"\"\n","  Loads an image and prepares it for use with EfficientNet.\n","  Returns a numpy image.\n","  \"\"\"\n","  image = keras.preprocessing.image.load_img(image_path, target_size=INPUT_DIMS)\n","  image = keras.preprocessing.image.img_to_array(image)\n","  image = keras.applications.efficientnet.preprocess_input(image)\n","  return image\n","\n","def load_image_set(set_path, label, count):\n","  \"\"\"\n","  Loads an image dataset.\n","  Inputs:\n","      set_path   string; folder where dataset lives\n","      label      string; category label associated with these images\n","      count      integer; maximum number of images to load; -1 means load all images in folder\n","  Returns:\n","      Pair (images, labels) where\n","          images is a list of numpy images\n","          labels is a list of strings\n","  \"\"\"  \n","  # get name of all files in set_path\n","  filenames = tf.io.gfile.listdir(set_path)\n","\n","  # loop over the images\n","  data = []\n","  labels = []\n","  for filename in filenames:\n","    # load the input image and preprocess it\n","    image = load_image(os.path.join(set_path, filename))\n","    # update the data and labels lists, respectively\n","    data.append(image)\n","    labels.append(label)\n","    # check the image count\n","    count = count - 1\n","    if count == 0:\n","      break\n","\n","  return data, labels"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Om-JCU66uPGW"},"source":["Load the dataset from disk.  The DATASET_PATH folder contains two subfolders, 'background' and 'present'.  Inside the subfolders are JPEG images."]},{"cell_type":"code","metadata":{"id":"LEobHuQuuTn8"},"source":["# load the image dataset\n","data, labels = load_image_set(DATASET_PATH + \"/present\", \"present\", IMAGE_COUNT)\n","data1, labels1 = load_image_set(DATASET_PATH + \"/background\", \"background\", IMAGE_COUNT)\n","data.extend(data1)\n","labels.extend(labels1)\n","\n","# convert the data and labels to NumPy arrays\n","data = np.array(data, dtype=\"float32\")\n","labels = np.array(labels)\n","\n","# perform one-hot encoding on the labels\n","lb = LabelBinarizer()\n","labels = lb.fit_transform(labels)\n","labels = keras.utils.to_categorical(labels)\n","\n","# save the label binarizer to a pickle file\n","f = open(LABEL_ENCODER_PATH, \"wb\")\n","f.write(pickle.dumps(lb))\n","f.close()\n","\n","# partition the data into training, validation and testing sets\n","(trainX_full, testX, trainY_full, testY) = train_test_split(data, labels,\ttest_size=0.20, random_state=42)\n","(trainX, validationX, trainY, validationY) = train_test_split(trainX_full, trainY_full,\ttest_size=0.20, random_state=42)\n","print(len(trainY), \"images in training set\")\n","print(len(validationY), \"images in validation set\")\n","print(len(testY), \"images in test set\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uyDiTxFqyk_D"},"source":["Create the new model based on EfficientNetB0"]},{"cell_type":"code","metadata":{"id":"GYD1OfwwyuH-"},"source":["# load the EfficientNetB0 network, ensuring the head layers are left off\n","baseModel = keras.applications.EfficientNetB0(weights=\"imagenet\", include_top=False,\n","\t input_tensor=keras.layers.Input(shape=(224, 224, 3)))\n","\n","# construct the head of the model that will be placed on top of the\n","# the base model\n","headModel = baseModel.output\n","headModel = keras.layers.AveragePooling2D(pool_size=(7, 7))(headModel)\n","headModel = keras.layers.Flatten(name=\"flatten\")(headModel)\n","headModel = keras.layers.Dense(128, activation=\"relu\")(headModel)\n","headModel = keras.layers.Dropout(0.5)(headModel)\n","headModel = keras.layers.Dense(2, activation=\"softmax\")(headModel)\n","\n","# place the new head on top of the base model (this will become the actual model we will train)\n","model = keras.models.Model(inputs=baseModel.input, outputs=headModel)\n","  "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"84QaoeNK0h38"},"source":["Phase 1 training, on the head of the model"]},{"cell_type":"code","metadata":{"id":"kehu18lNzkEI"},"source":["# freeze the layers in the base model so they will *not* be updated during the first training process\n","for layer in baseModel.layers:\n","\tlayer.trainable = False  \n","\n","# compile our model\n","model.compile(\n","    loss=\"binary_crossentropy\", \n","    optimizer=keras.optimizers.Adam(learning_rate=PHASE1_LR), \n","    metrics=[\"accuracy\"])\n","model.summary()\n","\n","# train the head of the network\n","history = model.fit(trainX, trainY,\n","\tvalidation_data=(validationX, validationY),\n","\tepochs=PHASE1_EPOCHS)  \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lGN6MyzI0ku1"},"source":["Evaluate the performance of the model"]},{"cell_type":"code","metadata":{"id":"yn3ydqUN0oLg"},"source":["print(\"\\nEvaluate Phase 1 model performance\")\n","\n","# predict the class of each example in the test set\n","predY = np.argmax(model.predict(testX), axis=1)\n","\n","# show a nicely formatted classification report\n","print(classification_report(testY.argmax(axis=1), predY, target_names=lb.classes_))  \n","\n","# plot the training history\n","pandas.DataFrame(history.history).plot() \n","plt.grid(True)\n","plt.title(\"Phase 1 Training Performance\")\n","plt.xlabel(\"Epoch\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QaKkivVco6tV"},"source":["Phase 2 of training, where we fine-tune the weights in the convolutional layers."]},{"cell_type":"code","metadata":{"id":"vEq-34jypDgv"},"source":["# unfreeze the layers of the base model\n","for layer in baseModel.layers:\n","\tlayer.trainable = True  \n","\n","# compile our model again\n","model.compile(\n","    loss=\"binary_crossentropy\", \n","    optimizer=keras.optimizers.Adam(learning_rate=PHASE2_LR), \n","    metrics=[\"accuracy\"])   \n","\n","# train the entire network\n","history = model.fit(trainX, trainY,\n","\tvalidation_data=(validationX, validationY),\n","\tepochs=PHASE2_EPOCHS)  "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z2fUdM-KpJaZ"},"source":["Evaluate the performance of the fine-tuned model"]},{"cell_type":"code","metadata":{"id":"bUYUwe4LpOVf"},"source":["print(\"\\nEvaluate Phase 2 model performance\")\n","\n","# predict the class of each example in the test set\n","predY = np.argmax(model.predict(testX), axis=1)\n","\n","# show a nicely formatted classification report\n","print(classification_report(testY.argmax(axis=1), predY, target_names=lb.classes_))    \n"," \n","# plot the training history\n","pandas.DataFrame(history.history).plot() \n","plt.grid(True)\n","plt.title(\"Phase 2 Training Performance\")\n","plt.xlabel(\"Epoch\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YE5sQhehpSwC"},"source":["Save the model.  A warning will be printed regarding custom masks; you can ignore this warning, as it does not pertain to this script."]},{"cell_type":"code","metadata":{"id":"M11KZj2WpUHm"},"source":["model.save(SAVED_MODEL_PATH) "],"execution_count":null,"outputs":[]}]}